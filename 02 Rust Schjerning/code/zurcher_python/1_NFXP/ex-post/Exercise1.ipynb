{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "# magics: ensures that any changes to the modules loaded below will be re-loaded automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext line_profiler\n",
    "\n",
    "# load general packages\n",
    "import numpy as np\n",
    "\n",
    "# load modules related to this exercise\n",
    "from model_zucher import zurcher\n",
    "from Solve_NFXP import solve_NFXP\n",
    "import estimate_NFXP as estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Look at ReadMe.txt to get an overview of the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Invistigate how the code works, that is ensure you understand:\n",
    "<il type =\"a\">\n",
    "<li> zurcher.init</li>\n",
    "<li> zurcher.setup</li>\n",
    "<li> zurcher.create_grid</li>\n",
    "<li> zucher.state_transition </li>\n",
    "<li> zucher.bellman </li>\n",
    "\n",
    "You can see how they are called below\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Fill in the missing stuff in the function zucher.bellman and run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model grid:\n",
      " [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "Transition probabilities conditional on not replacing:\n",
      " [[0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05 0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.1  0.05]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.2  0.15]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.65 0.35]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]]\n",
      "Transition probabilities conditional on replacing:\n",
      " [[0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.65 0.2  0.1  0.05 0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "Bellman one run:\n",
      " [0.47323702 0.47170994 0.47018428 0.46866004 0.46713722 0.46561582\n",
      " 0.46409584 0.46257729 0.46106015 0.45962006 0.45833254 0.45734867]\n"
     ]
    }
   ],
   "source": [
    "do_settings = {\n",
    "    'RC': 0.5,\n",
    "    'n': 12,\n",
    "    'p':[0.65,0.2,0.1]   \n",
    "}\n",
    "model = zurcher(**do_settings)\n",
    "\n",
    "print('Model grid:\\n',model.grid)\n",
    "print('Transition probabilities conditional on not replacing:\\n',model.P1)\n",
    "print('Transition probabilities conditional on replacing:\\n',model.P2)\n",
    "ev,pk, dev = model.bellman(np.zeros((model.n)),output=3)\n",
    "print('Bellman one run:\\n',ev)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "### 4. Solve the model. In order to solve the model, you should understand:\n",
    "<li> solve_NFXP.init</li>\n",
    "<li> solve_NFXP.setup</li>\n",
    "<li> solve_NFXP.poly </li>\n",
    "<li> solve_NFXP.sa </li>\n",
    "<li> solve_NFXP.nk </li>\n",
    "</il>\n",
    "You can see how they are called below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin contraction iterations (for the 1 time)\n",
      "Iteration 1, tol     0.4273, tol(j)/tol(j-1)          1\n",
      "Iteration 2, tol     0.4272, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 3, tol     0.4272, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 4, tol     0.4271, tol(j)/tol(j-1)     0.9999\n",
      "Iteration 5, tol     0.4271, tol(j)/tol(j-1)     0.9998\n",
      "Iteration 6, tol      0.427, tol(j)/tol(j-1)     0.9998\n",
      "Iteration 7, tol     0.4269, tol(j)/tol(j-1)     0.9998\n",
      "Iteration 8, tol     0.4268, tol(j)/tol(j-1)     0.9997\n",
      "Iteration 9, tol     0.4266, tol(j)/tol(j-1)     0.9996\n",
      "Iteration 10, tol     0.4264, tol(j)/tol(j-1)     0.9995\n",
      "Iteration 11, tol     0.4261, tol(j)/tol(j-1)     0.9994\n",
      "Iteration 12, tol     0.4258, tol(j)/tol(j-1)     0.9991\n",
      "Iteration 13, tol     0.4253, tol(j)/tol(j-1)     0.9988\n",
      "Iteration 14, tol     0.4246, tol(j)/tol(j-1)     0.9984\n",
      "Iteration 15, tol     0.4237, tol(j)/tol(j-1)     0.9978\n",
      "Iteration 16, tol     0.4224, tol(j)/tol(j-1)      0.997\n",
      "Iteration 17, tol     0.4207, tol(j)/tol(j-1)      0.996\n",
      "Iteration 18, tol     0.4185, tol(j)/tol(j-1)     0.9947\n",
      "Iteration 19, tol     0.4156, tol(j)/tol(j-1)      0.993\n",
      "Iteration 20, tol     0.4119, tol(j)/tol(j-1)      0.991\n",
      "Maximum number of iterations reached, tolerance: 0.4119\n",
      "Elapsed time 0.0499 seconds\n",
      "Begin Newton-Kantorovich iterations (for the 1 time)\n",
      "Iteration 1, tol     0.9393, tol(j)/tol(j-1)          1\n",
      "Iteration 2, tol       0.13, tol(j)/tol(j-1)     0.1384\n",
      "Iteration 3, tol    0.02133, tol(j)/tol(j-1)      0.164\n",
      "Iteration 4, tol  0.0006562, tol(j)/tol(j-1)    0.03077\n",
      "Iteration 5, tol  2.616e-07, tol(j)/tol(j-1)  0.0003986\n",
      "Iteration 6, tol  1.364e-12, tol(j)/tol(j-1)  5.216e-06\n",
      "N-K converged after 6 iterations, tolerance: 1.364e-12\n",
      "Elapsed time 0.0317 seconds\n",
      "Convergence achieved!\n",
      "Elapsed time: 0.0844 (seconds)\n"
     ]
    }
   ],
   "source": [
    "algorithm = 'poly'\n",
    "do_settings_solver = {\n",
    "    'sa_min': 10,\n",
    "    'sa_max': 20,  \n",
    "    'printfxp': 2\n",
    "}\n",
    "\n",
    "solver = solve_NFXP(**do_settings_solver)\n",
    "model = zurcher()\n",
    "\n",
    "if algorithm == 'sa':\n",
    "    ev = solver.sa(model.bellman)\n",
    "if algorithm == 'poly':\n",
    "    ev = solver.poly(model.bellman)\n",
    "else:\n",
    "    print('Algorithm must be \"sa\" or \"poly\"')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Now we have to estimate the model. In order to estimate the model, you should understand:\n",
    "<il type =\"a\">\n",
    "<li> zurcher.read_busdata </li>\n",
    "<li> estimate_NFXP.estimate  </li>\n",
    "<li> estimate_NFXP.ll  </li>\n",
    "</il>\n",
    "\n",
    "You can see how they are called below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fill in the missing stuff in the function estimate_NFXP.ll, and estimate the model to check that your results are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Structual estimation using busdata from Rust(1987)\n",
      "Beta        = 0.9999\n",
      "n           = 175\n",
      "Sample size = 8156\n",
      " \n",
      "\n",
      "Parameters     Estimates    s.e. \n",
      "RC             9.8673     1.2072 \n",
      "c              1.3408     0.3199 \n",
      " \n",
      "p(1)           0.1069     0.0034  \n",
      "p(2)           0.5154     0.0055  \n",
      "p(3)           0.3621     0.0053  \n",
      "p(4)           0.0143     0.0013  \n",
      "\n",
      "Log-likelihood -8605.96\n",
      "runtime (seconds) 1.5502\n",
      "The model converged: True\n"
     ]
    }
   ],
   "source": [
    "# Set up the model\n",
    "model = zurcher()\n",
    "\n",
    "# Set-up solver\n",
    "solver = solve_NFXP()\n",
    "\n",
    "# Read the data\n",
    "data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "samplesize = data.shape[0]\n",
    "\n",
    "# Estimate the model\n",
    "import time\n",
    "t0 = time.time()\n",
    "theta0 = [0,0]\n",
    "\n",
    "# args for nfxp estimate\n",
    "nfxp_model, optim_res, pnames, theta_hat, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "t1 = time.time()\n",
    "time = t1-t0\n",
    "\n",
    "# Print the result\n",
    "print(f'Structual estimation using busdata from Rust(1987)')\n",
    "print(f'Beta        = {model.beta:.4f}')\n",
    "print(f'n           = {model.n}')\n",
    "print(f'Sample size = {samplesize}\\n \\n')\n",
    "\n",
    "print(f'Parameters     Estimates    s.e. ') \n",
    "print(f'{pnames[0]}             {theta_hat[0]:.4f}     {np.sqrt(Avar[0,0]):.4f} ')\n",
    "print(f'{pnames[1]}              {theta_hat[1]:.4f}     {np.sqrt(Avar[1,1]):.4f} \\n ')\n",
    "print(f'{pnames[2]}(1)           {theta_hat[2]:.4f}     {np.sqrt(Avar[2,2]):.4f}  ')\n",
    "print(f'{pnames[2]}(2)           {theta_hat[3]:.4f}     {np.sqrt(Avar[3,3]):.4f}  ')\n",
    "print(f'{pnames[2]}(3)           {theta_hat[4]:.4f}     {np.sqrt(Avar[4,4]):.4f}  ')\n",
    "print(f'{pnames[2]}(4)           {theta_hat[5]:.4f}     {np.sqrt(Avar[5,5]):.4f}  \\n')\n",
    "\n",
    "\n",
    "print(f'Log-likelihood {-optim_res.fun*samplesize:.2f}') \n",
    "print(f'runtime (seconds) {time:.4f}')\n",
    "print(f'The model converged: {converged}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Try using line_profiler in python. This gives you a lot of information about the performance of your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-07 s\n",
       "\n",
       "Total time: 1.88026 s\n",
       "File: C:\\Users\\czk481\\Documents\\PhD\\TA\\Excercise 2020\\3. NFXP\\expost\\estimate_NFXP.py\n",
       "Function: estimate at line 9\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     9                                           def estimate(model,solver,data,theta0=[0,0],twostep=0):\n",
       "    10                                               global ev\n",
       "    11         1        280.0    280.0      0.0      ev = np.zeros(1) \n",
       "    12                                               \n",
       "    13         1        268.0    268.0      0.0      samplesize = data.shape[0]\n",
       "    14                                               # STEP 1: Find p \n",
       "    15         1      31376.0  31376.0      0.2      tabulate = data.dx1.value_counts()\n",
       "    16         1       7517.0   7517.0      0.0      p = [tabulate[i]/sum(tabulate) for i in range(tabulate.size-1)]\n",
       "    17                                           \n",
       "    18                                               # STEP 2: Estimate structual parameters\n",
       "    19         1         49.0     49.0      0.0      model.p = p # Use first step estimates as starting values for p\n",
       "    20                                               \n",
       "    21                                               # Estimate RC and C\n",
       "    22         1         23.0     23.0      0.0      pnames = ['RC','c']\n",
       "    23                                               \n",
       "    24         1   10854246.0 10854246.0     57.7      res = optimize.minimize(ll,theta0,args = (model, solver, data, pnames), method = 'trust-ncg',jac = grad, hess = hes, tol=1e-8)\n",
       "    25         1        294.0    294.0      0.0      model=updatepar(model,pnames,res.x)\n",
       "    26                                               \n",
       "    27                                               # Estimate RC, c and p\n",
       "    28         1         26.0     26.0      0.0      if twostep == 0:\n",
       "    29         1         31.0     31.0      0.0          pnames = ['RC','c','p']\n",
       "    30         1         74.0     74.0      0.0          theta0 = [model.RC, model.c] + model.p.tolist()\n",
       "    31         1    7680559.0 7680559.0     40.8          res = optimize.minimize(ll,theta0, args = (model,solver,data, pnames), method = 'trust-ncg',jac = grad, hess = hes, tol = 1e-8)\n",
       "    32                                           \n",
       "    33         1        419.0    419.0      0.0          model=updatepar(model,pnames,res.x)\n",
       "    34                                           \n",
       "    35                                               # Converged\n",
       "    36         1         60.0     60.0      0.0      converged   =   (res.status == 2 or res.status ==0)\n",
       "    37                                           \n",
       "    38                                               # Compute Variance-Covaiance matrix\n",
       "    39         1     226025.0 226025.0      1.2      h = hes(res.x, model, solver,data, pnames)\n",
       "    40         1       1186.0   1186.0      0.0      Avar = np.linalg.inv(h*samplesize)\n",
       "    41                                           \n",
       "    42         1        130.0    130.0      0.0      theta_hat = res.x\n",
       "    43                                               \n",
       "    44         1         29.0     29.0      0.0      return model, res, pnames, theta_hat, Avar, converged\n",
       "\n",
       "Total time: 1.64858 s\n",
       "File: C:\\Users\\czk481\\Documents\\PhD\\TA\\Excercise 2020\\3. NFXP\\expost\\estimate_NFXP.py\n",
       "Function: ll at line 46\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    46                                           def ll(theta, model, solver,data, pnames, out=1): # out=1 solve optimization\n",
       "    47                                               global ev\n",
       "    48                                               \n",
       "    49                                               #Update model parameters\n",
       "    50       109      65772.0    603.4      0.4      x = data.x\n",
       "    51       109      36029.0    330.5      0.2      d = data.d\n",
       "    52       109      32984.0    302.6      0.2      dx1 = data.dx1\n",
       "    53                                           \n",
       "    54       109      26416.0    242.3      0.2      model=updatepar(model,pnames,theta)\n",
       "    55       109      12819.0    117.6      0.1      model.p = np.abs(model.p)    # helps BHHH which is run as unconstrained optimization\n",
       "    56                                           \n",
       "    57                                               # Update values\n",
       "    58       109    1507244.0  13827.9      9.1      model.create_grid()\n",
       "    59       109       3283.0     30.1      0.0      ev0 = ev\n",
       "    60                                           \n",
       "    61                                               # Solve the model\n",
       "    62       109   11558728.0 106043.4     70.1      ev, pk, dev = solver.poly(model.bellman, V0=ev0 ,beta=model.beta, output=3)\n",
       "    63                                           \n",
       "    64                                               # Evaluate likelihood function\n",
       "    65       109     153283.0   1406.3      0.9      lik_pr = pk[x]    \n",
       "    66       109    2207443.0  20251.8     13.4      log_lik = np.log(lik_pr+(1-2*lik_pr)*d+1e-15)       # + 1e-15 add a small number, which makes it more robust to log_lik(0)\n",
       "    67                                           \n",
       "    68                                               # add on log like for mileage process\n",
       "    69       109       4484.0     41.1      0.0      if theta.size>2:\n",
       "    70        42      31177.0    742.3      0.2          p = np.append(model.p,1-np.sum(model.p))\n",
       "    71        42       7954.0    189.4      0.0          if any(p<=0):\n",
       "    72         7      67168.0   9595.4      0.4              log_lik -= 100000*p[dx1]\n",
       "    73                                                   else:\n",
       "    74        35     342508.0   9785.9      2.1              log_lik += np.log(p[dx1])\n",
       "    75                                                   \n",
       "    76                                               else:\n",
       "    77        67       1426.0     21.3      0.0          p = np.nan\n",
       "    78                                           \n",
       "    79                                           \n",
       "    80       109       2495.0     22.9      0.0      if out == 1:\n",
       "    81                                                   # Objective function (negative mean log likleihood)\n",
       "    82        70     423685.0   6052.6      2.6          return np.mean(-log_lik)\n",
       "    83                                           \n",
       "    84        39        858.0     22.0      0.0      return model,lik_pr, pk, ev, dev, d,x,dx1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f estimate.ll  -f estimate.estimate estimate.estimate(model, solver,data,theta0=theta0, twostep=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-07 s\n",
       "\n",
       "Total time: 0.015125 s\n",
       "File: C:\\Users\\czk481\\Documents\\PhD\\TA\\Excercise 2020\\3. NFXP\\expost\\Solve_NFXP.py\n",
       "Function: poly at line 30\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    30                                               def poly(self,bellman, V0=np.zeros(1), beta= 0.0, output=1):\n",
       "    31                                           \n",
       "    32         1         28.0     28.0      0.0          t0poly = time.time()  # set the starting time\n",
       "    33                                           \n",
       "    34         6         65.0     10.8      0.0          for k in range(self.max_fxpiter):\n",
       "    35                                           \n",
       "    36                                                       # 1. CONTRACTION ITERATIONS (S-A)\n",
       "    37         5         37.0      7.4      0.0              if self.printfxp>0:\n",
       "    38                                                           print(f'Begin contraction iterations (for the {k+1} time)')\n",
       "    39         5      64491.0  12898.2     42.6              V0,iter_sa= self.sa(bellman,V0,beta)\n",
       "    40                                           \n",
       "    41                                                       # 2. NEWTON-KANTOROVICH ITERATIONS\n",
       "    42         5         71.0     14.2      0.0              if self.printfxp>0:\n",
       "    43                                                           print(f'Begin Newton-Kantorovich iterations (for the {k+1} time)')\n",
       "    44         5      86365.0  17273.0     57.1              V0,pk,dV, iter_nk = self.nk(bellman,V0)\n",
       "    45                                           \n",
       "    46                                           \n",
       "    47         5         59.0     11.8      0.0              t1poly = time.time()\n",
       "    48         5         54.0     10.8      0.0              if iter_nk.converged=='true':\n",
       "    49         5         49.0      9.8      0.0                  if self.printfxp>0:\n",
       "    50                                                               print(f'Convergence achieved!')\n",
       "    51                                                               print(f'Elapsed time: {(t1poly-t0poly):.4f} (seconds)')\n",
       "    52                                                               break \n",
       "    53                                                       else:\n",
       "    54                                                           if k >= self.max_fxpiter:\n",
       "    55                                                               print(f'No convergence! Maximum number of iterations exceeded without convergence!')\n",
       "    56                                                               break\n",
       "    57         1          8.0      8.0      0.0          V = V0\n",
       "    58         1         10.0     10.0      0.0          if output==1:            \n",
       "    59         1         13.0     13.0      0.0              return V\n",
       "    60                                                   if output==2:            \n",
       "    61                                                       return V, pk\n",
       "    62                                                   if output==3:            \n",
       "    63                                                       return V, pk, dV\n",
       "    64                                                   if output==5:            \n",
       "    65                                                       return V, pk, dV, iter_sa, iter_nk\n",
       "    66                                                   else:\n",
       "    67                                                       print('solve_NFXP.poly: output must be 1,2,3 or 5')\n",
       "\n",
       "Total time: 0.0083929 s\n",
       "File: C:\\Users\\czk481\\Documents\\PhD\\TA\\Excercise 2020\\3. NFXP\\expost\\Solve_NFXP.py\n",
       "Function: nk at line 106\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   106                                               def nk(self,bellman, V0):\n",
       "   107         5        878.0    175.6      1.0          class iteration: pass\n",
       "   108         5         70.0     14.0      0.1          t0 = time.time()\n",
       "   109         5        437.0     87.4      0.5          iteration.tol =  np.nan+np.zeros((self.pi_max))\n",
       "   110         5        238.0     47.6      0.3          iteration.rtol = np.nan+np.zeros((self.pi_max))\n",
       "   111         5         60.0     12.0      0.1          iteration.converged = 'false'\n",
       "   112                                           \n",
       "   113         5         76.0     15.2      0.1          m = V0.size\n",
       "   114                                           \n",
       "   115         8        168.0     21.0      0.2          for i in range(self.pi_max):\n",
       "   116                                           \n",
       "   117                                                       # Do N-K step\n",
       "   118         8      14120.0   1765.0     16.8              V1, pk, dV = bellman(V0,output=3)\n",
       "   119         8       4723.0    590.4      5.6              F = np.eye(m)-dV\n",
       "   120         8      49734.0   6216.8     59.3              V = V0 - np.linalg.inv(F) @ (V0 - V1) \n",
       "   121                                                       \n",
       "   122                                                       # do additional SA iteration for stability and accurate measure of error bound\n",
       "   123         8       4550.0    568.8      5.4              V0 = bellman(V,output=1)\n",
       "   124                                           \n",
       "   125                                                       # Tolerance\n",
       "   126         8       3085.0    385.6      3.7              iteration.tol[i]=max(abs(V-V0))\n",
       "   127         8        383.0     47.9      0.5              iteration.rtol[i] = iteration.tol[i]/(iteration.tol[max(i-1,0)] + 1.0e-15)      \n",
       "   128                                           \n",
       "   129                                                       #Adjust \n",
       "   130         8       3223.0    402.9      3.8              adj  = np.ceil(np.log10(abs(max(V0))))\n",
       "   131         8        351.0     43.9      0.4              ltol = self.pi_tol*10**adj  # Adjust final tolerance\n",
       "   132                                           \n",
       "   133         8        141.0     17.6      0.2              if iteration.tol[i] < ltol:\n",
       "   134                                                           #Convergence achieved\n",
       "   135         5        724.0    144.8      0.9                  iteration.message = \"N-K converged after {} iterations, tolerance: {:.4g}\".format(i+1,iteration.tol[i])\n",
       "   136         5         77.0     15.4      0.1                  iteration.converged = 'true'\n",
       "   137         5         65.0     13.0      0.1                  break\n",
       "   138                                                   \n",
       "   139         5         77.0     15.4      0.1          iteration.n = i+1\n",
       "   140         5        161.0     32.2      0.2          iteration.tol = iteration.tol[0:i+1]\n",
       "   141         5         95.0     19.0      0.1          iteration.rtol = iteration.rtol[0:i+1]\n",
       "   142         5        133.0     26.6      0.2          t1 = time.time()\n",
       "   143         5         80.0     16.0      0.1          iteration.time = t1-t0 \n",
       "   144                                           \n",
       "   145         5        210.0     42.0      0.3          self.print_output(iteration)\n",
       "   146                                           \n",
       "   147         5         70.0     14.0      0.1          return V, pk, dV, iteration"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f solve_NFXP.nk -f solve_NFXP.poly solve_NFXP.poly(solver,model.bellman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Now try changing the optimizer options, and turn the use of the non-numerical Hessian off . What happens?\n",
    "\n",
    "b) Now also try it with the analytical gradient off, what happens?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alternative_specifications_ex7 as a_s_ex7\n",
    "\n",
    "model = zurcher()\n",
    "solver = solve_NFXP()\n",
    "\n",
    "#Ordinaty\n",
    "print('BHHH:')\n",
    "%timeit nfxp_results = a_s_ex7.estimate(model, solver,data,theta0=theta0, twostep=0,est_type=0)\n",
    "\n",
    "\n",
    "# Hessian off\n",
    "print('')\n",
    "print('Hessian is off:')\n",
    "%timeit nfxp_result = a_s_ex7.estimate(model, solver,data,theta0=theta0, twostep=0,est_type=1)\n",
    "\n",
    "\n",
    "#Hessian and gradient ofF \n",
    "print('')\n",
    "print('Hessian and gradient are off:')\n",
    "%timeit nfxp_results = a_s_ex7.estimate(model, solver,data,theta0=theta0, twostep=0,est_type=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Try estimate the model for different values of $\\beta$. \n",
    "\n",
    "(a) Why can we not estimate $\\beta$?\n",
    "\n",
    "(b) When estimating with different $\\beta$, do the changes in the estimates of c and/or RC make intuitively sense?\n",
    "\n",
    "(c) Can you think of some data/variation, which could allow us to identify $\\beta$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta     RC     C       log_lik\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\czk481\\Documents\\PhD\\TA\\Excercise 2020\\3. NFXP\\expost\\Solve_NFXP.py:91: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  iteration.rtol[i] = iteration.tol[i]/iteration.tol[max(i-1,0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5000 7.5909 264.2933 [-2721.09951922] \n",
      "0.6666 7.6582 181.4516 [-2720.76883952] \n",
      "0.8333 7.8442 98.6229 [-2719.86279673] \n",
      "0.9999 10.5537 18.3042 [-2714.57341967] \n"
     ]
    }
   ],
   "source": [
    "# VARY BETA: \n",
    "Nbeta = 4\n",
    "beta = np.linspace(0.5,0.9999,Nbeta)\n",
    "log_lik = np.nan + np.zeros((Nbeta,1))\n",
    "theta_hats =  np.nan + np.zeros((Nbeta,2))\n",
    "\n",
    "data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "samplesize = data.shape[0]\n",
    "\n",
    "print(f'beta     RC     C       log_lik')\n",
    "for i in range(Nbeta):\n",
    "    \n",
    "    # Set up the model\n",
    "    do_settings = {\n",
    "    'beta': beta[i]\n",
    "    }\n",
    "    model = zurcher(**do_settings)\n",
    "\n",
    "\n",
    "    # Set-up solver\n",
    "    solver = solve_NFXP()\n",
    "\n",
    "    # Estimate the model\n",
    "    theta0 = [0,0]\n",
    "    nfxp_model, optim_res, pnames, theta_hat, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "    \n",
    "    theta_hats[i,0] = theta_hat[0]\n",
    "    theta_hats[i,1] = theta_hat[1]\n",
    "    log_lik[i]=-optim_res.fun*samplesize\n",
    "    print(f'{beta[i]:.4f} {theta_hats[i,0]:.4f} {theta_hats[i,1]:.4f} {log_lik[i]} ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. We use the latest EV guess to start the solve-procedure even though we change $\\theta$ from one likelihood iteration to another. Why do you think we do that? \n",
    "(a) What if we started over with EV=0 each iteration? Try that and see what happens with the parameters and the numerical performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import alternative_specifications_ex9 as a_s_ex9 \n",
    "\n",
    "# Ordinary\n",
    "print('Same EV')\n",
    "%timeit a_s_ex9.estimate(model, solver,data,0)\n",
    "nfxp_results_ord, theta_hat_ord = a_s_ex9.estimate(model, solver,data,0)\n",
    "\n",
    "\n",
    "# Change EV=0 in each iteration\n",
    "print('EV=0')\n",
    "%timeit a_s_ex9.estimate(model, solver,data,1)\n",
    "nfxp_results_diff, theta_hat_diff = a_s_ex9.estimate(model, solver,data,1)\n",
    "\n",
    "print('')\n",
    "print(f'                 Same EV       EV=0')\n",
    "print(f'{pnames[0]}               {theta_hat_ord[0]:.4f}       {theta_hat_diff[0]:.4f}')\n",
    "print(f'{pnames[1]}                {theta_hat_ord[1]:.4f}       {theta_hat_diff[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Try setting the maximum number of miles (odometer reading) to 900. Now the absorbing state is much higher. \n",
    "\n",
    "(a) If we adjust the number of grid points as well, so that we have a comparable model (multiply the number of grids by 2), do we get a better fit? \n",
    "\n",
    "(b) Try to lower the number of grid points to 175 again. How do the parameters change? Are the changes intuitive? \n",
    "\n",
    "(c) What if you change the max to 225 and half the number of grids (hint: what goes wrong?)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for adjusting Grid-points\n",
    "def adjust_grid_point(maks, n):\n",
    "    # Set up the model\n",
    "    do_settings = {\n",
    "    'max': maks,\n",
    "    'n': n\n",
    "    }\n",
    "    model = zurcher(**do_settings)\n",
    "\n",
    "    # Set-up solver\n",
    "    solver = solve_NFXP()\n",
    "        \n",
    "    # Read the data\n",
    "    data = model.read_busdata(bustypes=[1,2,3,4])\n",
    "    samplesize = data.shape[0]\n",
    "\n",
    "    # Estimate the model\n",
    "    theta0 = [0,0]\n",
    "    nfxp_model, result, pnames, theta, Avar, converged=estimate.estimate(model, solver,data,theta0=theta0, twostep=0)\n",
    "\n",
    "    \n",
    "    print(f'Parameters     Estimates    s.e. ') \n",
    "    print(f'{pnames[0]}             {theta[0]:.4f}     {np.sqrt(Avar[0,0]):.4f} ')\n",
    "    print(f'{pnames[1]}              {theta[1]:.4f}     {np.sqrt(Avar[1,1]):.4f} \\n ')\n",
    "    print(f'Log-likelihood now {-result.fun*samplesize:.4f}\\n \\n') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline max = 450, n = 175\n",
    "print(f'Baseline')\n",
    "adjust_grid_point(450,175);\n",
    "\n",
    "# a)  max = 900, n = 175*2\n",
    "print(f'Question (a)')\n",
    "adjust_grid_point(450*2,175*2)\n",
    "\n",
    "# b) max = 600, n = 175\n",
    "print(f'Question (b)')\n",
    "adjust_grid_point(600,175)\n",
    "\n",
    "# c) max =225, n = 175/2\n",
    "print(f'Question (c)')\n",
    "adjust_grid_point(int(450/2),int(175/2));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
